<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-AU">
  <head>
    <meta http-equiv="content-type" content="application/xhtml+xml; charset=UTF-8" />
    <meta name="author" content="haran" />
    <meta name="generator" content="haran" />

    <!-- Navigational metadata for large websites (an accessibility feature): -->
    <link rel="top"      href="./index.html" title="Homepage" />
    <link rel="up"       href="./index.html" title="Up" />
    <link rel="first"    href="./index.html" title="First page" />
    <link rel="previous" href="./index.html" title="Previous page" />
    <link rel="next"     href="./index.html" title="Next page" />
    <link rel="last"     href="./index.html" title="Last page" />
    <link rel="toc"      href="./index.html" title="Table of contents" />
    <link rel="index"    href="./index.html" title="Site map" />

    <link rel="stylesheet" type="text/css" href="./home-screen.css" media="screen" title="home (screen)" />
    <link rel="stylesheet" type="text/css" href="./home-print.css" media="print" />

    <title>home</title>
    <style type="text/css">
<!--
.style1 {color: #C1FF64}
-->
    </style>
</head>

  <body>
    <!-- For non-visual user agents: -->
      <div id="top"><a href="#main-copy" class="doNotDisplay doNotPrint">Skip to main content.</a></div>

    <!-- ##### Header ##### -->

    <div id="header">
      <h1 class="headerTitle">
        <a href="./index" title="Browse to homepage">ExplainIt: <span>Compares different methods for Model Interpretation</span></a>
      </h1>

      <div class="subHeader">
        <span class="doNotDisplay">Navigation: </span>
      </div>
    </div>

    <div id="side-bar">

      <!-- ##### Left Sidebar ##### -->

      <div class="leftSideBar">
        <p class="sideBarTitle">Methods explored</p>
        <ul>
          <li><a href="https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html">Sklearn Permutation Importance</a></li>
          <li><a href="https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/gbm.html">Gradient Boosting Machine (GBM)</a></li>
          <li><a href="https://github.com/slundberg/shap">SHAP</a></li>
          <li><a href="https://github.com/oracle/Skater">Skater</a></li>
        </ul>

      </div>


    </div>

    <!-- ##### Main Copy ##### -->

    <div id="main-copy">
      <h1 id="introduction" style="border-top: none; padding-top: 0;">Introduction</h1>
      <p>
        This module experiments several different methods to explain a ML model, and compares the performances.
      </p>

      <dt>Sklearn Permutation importance for feature evaluation </dt>
      <p>
        <a href="https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html">Permutation Importance</a>
        If we calculate feature importance by using sklearn rf impurity-based feature importances,
        that is by calling rf_model.feature_importances_ function, there are two limitations
        (<span style="color:red;">sklearn.ensemble.RandomForestClassifier</span> Parameter,
        criterion{“gini”, “entropy”}, default=”gini”):
        <span style="font-style:italic;color:blue;">
        1. impurity-based importances are biased towards high cardinality features;
        2. impurity-based importances are computed on training set statistics and therefore
        do not reflect the ability of feature to be useful to make predictions that generalize to the test set
        (when the model has enough capacity).
        </span>
        In Sklearn, using Permutation Importances as an alternative that can mitigate those limitations
        of the impurity-based feature importance of random forests.
        The permutation importance of a feature is calculated as follows.
        First, a baseline metric, defined by scoring, is evaluated on a (potentially different)
        dataset defined by the X. Next, a feature column from the validation set is permuted and the
        metric is evaluated again. The permutation importance is defined to be the difference between
        the baseline metric and metric from permutating the feature column.
      </p>
      <div class="image_sklearn">
        <div class="imageContainer">
        <div class="sklearnPlot">
          <img src="images/rf_importance.png" alt="rf impurity-based importance" width="590" height="450">
          </div>
        </div>

        <div class="imageContainer">
          <div class="sklearnPlot">
          <img src="images/permutation_importance.png" alt="permutation importance" width="590" height="450">
          </div>
        </div>
      </div>

      <br clear="all" />
      <dt>Feature Importance from GBM</dt>
      <p>
        <a href="https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/gbm.html">Gradient Boosting Machine (GBM)</a>
        Gradient Boosting Machine (for Regression and Classification) is a forward learning ensemble method.
        Variable importance is determined by calculating the relative influence of each variable:
        whether that variable was selected to split on during the tree building process,
        and how much the squared error (over all trees) improved (decreased) as a result.
      </p>

      <dt>SHAP (SHapley Additive exPlanations)</dt>
      <p>
        <a href="https://github.com/slundberg/shap">SHAP</a>
        is a game theoretic approach to explain the output of any machine learning model.
        It connects optimal credit allocation with local explanations using the classic Shapley values
        from game theory and their related extensions.
      </p>

      <dt>Skater </dt>
      <p>
        <a href="https://github.com/oracle/Skater">Skater</a>

        Model Interpretation could be enabled in multiple different ways, but at a highlevel it could be broadly categorized as,

        1. post hoc interpretation: Given a black box model trained to solve a supervised learning problem(X –> Y,
          where X is the input and Y is the output), post-hoc interpretation can be thought of as a function(f)
          ‘g’ with input data(D) and a predictive model.
          The function ‘g’ returns a visual or textual representation which helps in understanding the inner
          working of the model or why a certain outcome is more favorable than the other.
          It could also be called inspecting the black box or reverse engineering.
        2. natively interpretable models: Given a supervised learning problem,
        the predictive model(explanator function) has a transparent design and is
        interpretable both globally and locally without any further explanations.

        Skater is an open source python library designed to demystify the learned structures of a black box model
        both globally(inference on the basis of a complete data set) and locally(inference about an individual prediction).
      </p>
      <p>
      <span style="color:red;">pip install skater failed</span></span>,
      and git clone repo and install from local worked for me. Also, fixed couple other issues including
      install dependencies such as <span style="color:blue;">brew install graphviz</span></span>
      </p>

        </p>
      </p>
        </p>
      </p>
      <table >
      <thead><tr>
        <th>Scope of Interpretation</th>
        <th>Algorithms</th>
        </tr>
      </thead>
      <tbody>
      <tr>
        <td>Global Interpretation</td>
        <td>Model agnostic Feature Importance</td>
      </tr>
      <tr>
        <td>Global Interpretation</td>
        <td>Model agnostic Partial Dependence Plots</td>
      </tr>
      <tr>
        <td>Local Interpretation</td>
        <td>Local Interpretable Model Explanation(LIME)</td>
      </tr>
      <tr>
        <td>Local Interpretation</td>
        <td>DNNs:
        Layer-wise Relevance Propagation (e-LRP): image;
        Integrated Gradient: image and text;</td>
      </tr>
      <tr>
        <td>Global and Local Interpretation</td>
        <td>Scalable Bayesian Rule Lists; Tree Surrogates;</td>
      </tr>
      </tbody>
      </table>

      <dt>SKATER - Global Interpretations</dt>
      <div class="imageContainer">
        <img src="images/skater_global.png" alt="SKATER - Global Interpretations" width="820" height="320">
      </div>
      <div class="imageContainer">
        <img src="images/skater_global_2.png" alt="SKATER - Global Interpretations 2" width="890" height="350">
      </div>

      <dt>SKATER visualization on feature interactions</dt>
      <div class="imageContainer">
        <img src="images/interaction.png" alt="SKATER - Global Interpretations" width="1020" height="450">
      </div>

      <h1 id="cross-browser">Future Works</h1>
      <p>Placeholder</p>


      <h1 id="stylesheets">Cheat Sheet: 3 Decision Tree Splitting criterions</h1>
      <dl>
        <dt>1. Gini Impurity</dt>
        <dd>Gini impurity is a measure of how often a randomly chosen element
        from the set would be incorrectly labeled if it was randomly labeled
        according to the distribution of labels in the subset.</dd>
        <img src="images/gini_impurity.png" alt="gini impurity expained" width="450" height="350">

        <dt>2. Entropy</dt>
        <dd>Another very popular way to split nodes in the decision tree is Entropy.
        Entropy is the measure of Randomness in the system. </dd>


        <dt>3. Variance</dt>
        <dd>Gini Impurity and Entropy work pretty well for the classification scenario.
          But what about regression? In the case of regression,
          the most common split measure used is just the weighted variance of the nodes.
          </dd>
      </dl>

      <h1 id="accessibility">Resources</h1>

      <ul>
        <li><a href="https://www.kaggle.com/nareshbhat/health-care-data-set-on-heart-attack-possibility?select=heart.csv">
          <b>Kaggle Dataset: Health care Data set on Heart attack possibility</b>
          </a>
        </li>

        <li><a href="https://towardsdatascience.com/explainable-artificial-intelligence-part-3-hands-on-machine-learning-model-interpretation-e8ebe5afc608">
          <b>Hands-on Machine Learning Model Interpretation</b>
          </a>
        </li>
      </ul>

    </div>

    <!-- ##### Footer ##### -->

    <div id="footer">

      <div>
        Copyright &copy; 2020, explainit |
        Modified on 2020-July-07 by
          <a href="ruxiz2005@gmail.com" title="Email the author">zruxi</a>
      </div>
    </div>
  </body>
</html>
